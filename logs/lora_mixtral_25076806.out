Running LoRA fine-tuning on a100gpu3
================================================================================

[1;36m                             Loading configuration                              [0m

================================================================================
================================================================================

[1;32m                             Configuration settings                             [0m

================================================================================
EMOTION_ANALYSIS:
  ENABLE_PLOTTING: true
  LANGUAGES:
  - en
  - nl
  - hu
  - ro
GENERAL:
  DATA_DIR: '!OriginalData'
  MODELS_DIR: models
  OUTPUT_DIR: data
  PLOTS_DIR: plots
  SEED: 42
  TEST_SIZE: 0.2
LORA:
  BATCH_SIZE: 1
  DEVICE_IDS: '0'
  GRAD_ACCUM_STEPS: 16
  LEARNING_RATE: 5e-4
  LORA_ALPHA: 32
  LORA_DROPOUT: 0.05
  LORA_FINETUNE: false
  LORA_MODELS:
    ministral_3b: mistralai/Ministral-3B-v0.1
    mistral_tiny: mistralai/Mistral-3B-Instruct-v0.1
  LORA_RANK: 16
  NUM_EPOCHS: 4
PROMPTING:
  DEVICE: null
  ENABLE_PROMPTING: true
  FEW_SHOT_EXAMPLES:
  - label: surprise
    text: I can't believe this happened!
  - label: joy, trust
    text: I'm so happy for you!
  - label: anger
    text: This is so unfair.
  FEW_SHOT_INTRO: 'You are an emotion classifier. Here are examples:

    '
  INSTRUCTION_TEXT: 'You are a precise emotion classifier. Identify all emotions in
    the sentence based on Plutchik''s 8 basic emotions and return them as comma-separated
    values from: joy, trust, fear, surprise, sadness, disgust, anger, anticipation.

    '
  MAX_NEW_TOKENS: 64
  MODEL_NAME: mistralai/Mistral-7B-Instruct-v0.1

================================================================================

[1;32m                             Analyzing emotion data                             [0m

================================================================================
Loaded dataset: !OriginalData/en-projections.tsv (7834 rows)
Counted 8 unique emotions
Saved plot to: plots/emotion_distribution_en.png
Loaded dataset: !OriginalData/nl-projections.tsv (5334 rows)
Counted 8 unique emotions
Saved plot to: plots/emotion_distribution_nl.png
Loaded dataset: !OriginalData/hu-projections.tsv (5778 rows)
Counted 8 unique emotions
Saved plot to: plots/emotion_distribution_hu.png
Loaded dataset: !OriginalData/ro-projections.tsv (9475 rows)
Counted 8 unique emotions
Saved plot to: plots/emotion_distribution_ro.png
Saved emotion distribution plots to 'plots/'
================================================================================

[1;36m                           Emotion Data Preprocessing                           [0m

================================================================================
Processing en from !OriginalData/en-projections.tsv ...
  Saved train â†’ data/en/train.jsonl
  Saved validation â†’ data/en/validation.jsonl
  Saved test â†’ data/en/test.jsonl
Processing hu from !OriginalData/hu-projections.tsv ...
  Saved train â†’ data/hu/train.jsonl
  Saved validation â†’ data/hu/validation.jsonl
  Saved test â†’ data/hu/test.jsonl
Processing nl from !OriginalData/nl-projections.tsv ...
  Saved train â†’ data/nl/train.jsonl
  Saved validation â†’ data/nl/validation.jsonl
  Saved test â†’ data/nl/test.jsonl
Processing ro from !OriginalData/ro-projections.tsv ...
  Saved train â†’ data/ro/train.jsonl
  Saved validation â†’ data/ro/validation.jsonl
  Saved test â†’ data/ro/test.jsonl
================================================================================

[1;32m                             Preprocessing Complete                             [0m

================================================================================
================================================================================

[1;31m                    LoRA fine-tuning disabled in config.yaml                    [0m

================================================================================
================================================================================

[1;36m                        Evaluating Prompting Strategies                         [0m

================================================================================
Using device: cuda
Loading model: mistralai/Mistral-7B-Instruct-v0.1

Loading test datasets...

Evaluating on single-language dataset...

Evaluating strategy: zero-shot on 784 samples
Accuracy (zero-shot): 0.031

Evaluating strategy: few-shot on 784 samples
Accuracy (few-shot): 0.719

Evaluating strategy: instruction on 784 samples
