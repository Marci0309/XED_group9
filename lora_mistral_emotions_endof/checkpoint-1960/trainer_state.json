{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 200,
  "global_step": 1960,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1276324186343331,
      "grad_norm": 4.140974044799805,
      "learning_rate": 1e-05,
      "loss": 3.5911,
      "step": 50
    },
    {
      "epoch": 0.2552648372686662,
      "grad_norm": 1.4421006441116333,
      "learning_rate": 1.9999985766546288e-05,
      "loss": 1.7871,
      "step": 100
    },
    {
      "epoch": 0.3828972559029994,
      "grad_norm": 1.198053002357483,
      "learning_rate": 1.9963001615317968e-05,
      "loss": 1.5032,
      "step": 150
    },
    {
      "epoch": 0.5105296745373324,
      "grad_norm": 1.5044182538986206,
      "learning_rate": 1.98551555264863e-05,
      "loss": 1.4355,
      "step": 200
    },
    {
      "epoch": 0.5105296745373324,
      "eval_loss": 1.3886247873306274,
      "eval_runtime": 41.6712,
      "eval_samples_per_second": 18.79,
      "eval_steps_per_second": 9.407,
      "step": 200
    },
    {
      "epoch": 0.6381620931716656,
      "grad_norm": 1.302517056465149,
      "learning_rate": 1.9677214556317325e-05,
      "loss": 1.3266,
      "step": 250
    },
    {
      "epoch": 0.7657945118059988,
      "grad_norm": 1.2961034774780273,
      "learning_rate": 1.9430444311544034e-05,
      "loss": 1.2534,
      "step": 300
    },
    {
      "epoch": 0.8934269304403318,
      "grad_norm": 1.3168903589248657,
      "learning_rate": 1.911659994772724e-05,
      "loss": 1.2674,
      "step": 350
    },
    {
      "epoch": 1.0204211869814932,
      "grad_norm": 1.3446660041809082,
      "learning_rate": 1.873791368569603e-05,
      "loss": 1.2561,
      "step": 400
    },
    {
      "epoch": 1.0204211869814932,
      "eval_loss": 1.253631830215454,
      "eval_runtime": 41.8196,
      "eval_samples_per_second": 18.723,
      "eval_steps_per_second": 9.374,
      "step": 400
    },
    {
      "epoch": 1.1480536056158264,
      "grad_norm": 1.5183249711990356,
      "learning_rate": 1.8297078934857265e-05,
      "loss": 1.2391,
      "step": 450
    },
    {
      "epoch": 1.2756860242501595,
      "grad_norm": 2.0401203632354736,
      "learning_rate": 1.7797231136297228e-05,
      "loss": 1.233,
      "step": 500
    },
    {
      "epoch": 1.4033184428844927,
      "grad_norm": 1.7134838104248047,
      "learning_rate": 1.7241925461928994e-05,
      "loss": 1.2463,
      "step": 550
    },
    {
      "epoch": 1.5309508615188259,
      "grad_norm": 1.6000810861587524,
      "learning_rate": 1.663511152830059e-05,
      "loss": 1.229,
      "step": 600
    },
    {
      "epoch": 1.5309508615188259,
      "eval_loss": 1.2377524375915527,
      "eval_runtime": 41.9096,
      "eval_samples_per_second": 18.683,
      "eval_steps_per_second": 9.353,
      "step": 600
    },
    {
      "epoch": 1.658583280153159,
      "grad_norm": 2.169755220413208,
      "learning_rate": 1.598110530491216e-05,
      "loss": 1.2323,
      "step": 650
    },
    {
      "epoch": 1.786215698787492,
      "grad_norm": 1.9362770318984985,
      "learning_rate": 1.5284558416844518e-05,
      "loss": 1.223,
      "step": 700
    },
    {
      "epoch": 1.9138481174218251,
      "grad_norm": 1.7915223836898804,
      "learning_rate": 1.4550425060034367e-05,
      "loss": 1.2041,
      "step": 750
    },
    {
      "epoch": 2.0408423739629864,
      "grad_norm": 1.9872597455978394,
      "learning_rate": 1.3783926764511662e-05,
      "loss": 1.2144,
      "step": 800
    },
    {
      "epoch": 2.0408423739629864,
      "eval_loss": 1.2278691530227661,
      "eval_runtime": 42.3971,
      "eval_samples_per_second": 18.468,
      "eval_steps_per_second": 9.246,
      "step": 800
    },
    {
      "epoch": 2.1684747925973196,
      "grad_norm": 2.6459622383117676,
      "learning_rate": 1.299051525622081e-05,
      "loss": 1.1893,
      "step": 850
    },
    {
      "epoch": 2.2961072112316527,
      "grad_norm": 2.3403358459472656,
      "learning_rate": 1.2175833681571405e-05,
      "loss": 1.2053,
      "step": 900
    },
    {
      "epoch": 2.423739629865986,
      "grad_norm": 2.3186285495758057,
      "learning_rate": 1.1345676470509204e-05,
      "loss": 1.1623,
      "step": 950
    },
    {
      "epoch": 2.551372048500319,
      "grad_norm": 2.449629545211792,
      "learning_rate": 1.0505948123581594e-05,
      "loss": 1.1876,
      "step": 1000
    },
    {
      "epoch": 2.551372048500319,
      "eval_loss": 1.225009560585022,
      "eval_runtime": 42.4701,
      "eval_samples_per_second": 18.437,
      "eval_steps_per_second": 9.23,
      "step": 1000
    },
    {
      "epoch": 2.6790044671346522,
      "grad_norm": 2.5829567909240723,
      "learning_rate": 9.662621216124924e-06,
      "loss": 1.2039,
      "step": 1050
    },
    {
      "epoch": 2.8066368857689854,
      "grad_norm": 2.698143243789673,
      "learning_rate": 8.821693918269334e-06,
      "loss": 1.1885,
      "step": 1100
    },
    {
      "epoch": 2.9342693044033186,
      "grad_norm": 2.4341812133789062,
      "learning_rate": 7.989147332900321e-06,
      "loss": 1.1738,
      "step": 1150
    },
    {
      "epoch": 3.06126356094448,
      "grad_norm": 2.7746143341064453,
      "learning_rate": 7.170902955011274e-06,
      "loss": 1.1773,
      "step": 1200
    },
    {
      "epoch": 3.06126356094448,
      "eval_loss": 1.219844102859497,
      "eval_runtime": 43.6387,
      "eval_samples_per_second": 17.943,
      "eval_steps_per_second": 8.983,
      "step": 1200
    },
    {
      "epoch": 3.188895979578813,
      "grad_norm": 2.726813793182373,
      "learning_rate": 6.372780555017679e-06,
      "loss": 1.1365,
      "step": 1250
    },
    {
      "epoch": 3.316528398213146,
      "grad_norm": 3.080561637878418,
      "learning_rate": 5.600456785588273e-06,
      "loss": 1.1731,
      "step": 1300
    },
    {
      "epoch": 3.444160816847479,
      "grad_norm": 3.144131660461426,
      "learning_rate": 4.859424806402433e-06,
      "loss": 1.1823,
      "step": 1350
    },
    {
      "epoch": 3.5717932354818123,
      "grad_norm": 3.456481695175171,
      "learning_rate": 4.154955214003118e-06,
      "loss": 1.1504,
      "step": 1400
    },
    {
      "epoch": 3.5717932354818123,
      "eval_loss": 1.2193336486816406,
      "eval_runtime": 43.7479,
      "eval_samples_per_second": 17.898,
      "eval_steps_per_second": 8.96,
      "step": 1400
    },
    {
      "epoch": 3.6994256541161454,
      "grad_norm": 4.128603458404541,
      "learning_rate": 3.492058554632063e-06,
      "loss": 1.1649,
      "step": 1450
    },
    {
      "epoch": 3.8270580727504786,
      "grad_norm": 4.015475749969482,
      "learning_rate": 2.8754496866750836e-06,
      "loss": 1.1482,
      "step": 1500
    },
    {
      "epoch": 3.9546904913848118,
      "grad_norm": 3.8706648349761963,
      "learning_rate": 2.309514246189849e-06,
      "loss": 1.1532,
      "step": 1550
    },
    {
      "epoch": 4.081684747925973,
      "grad_norm": 4.052276611328125,
      "learning_rate": 1.7982774540304404e-06,
      "loss": 1.1487,
      "step": 1600
    },
    {
      "epoch": 4.081684747925973,
      "eval_loss": 1.2172096967697144,
      "eval_runtime": 42.5651,
      "eval_samples_per_second": 18.395,
      "eval_steps_per_second": 9.209,
      "step": 1600
    },
    {
      "epoch": 4.209317166560306,
      "grad_norm": 3.5889828205108643,
      "learning_rate": 1.3453754864282131e-06,
      "loss": 1.1416,
      "step": 1650
    },
    {
      "epoch": 4.336949585194639,
      "grad_norm": 3.761183738708496,
      "learning_rate": 9.540296126559977e-07,
      "loss": 1.1392,
      "step": 1700
    },
    {
      "epoch": 4.464582003828973,
      "grad_norm": 3.829087495803833,
      "learning_rate": 6.270232837217705e-07,
      "loss": 1.119,
      "step": 1750
    },
    {
      "epoch": 4.5922144224633055,
      "grad_norm": 4.159594535827637,
      "learning_rate": 3.6668233504858486e-07,
      "loss": 1.1318,
      "step": 1800
    },
    {
      "epoch": 4.5922144224633055,
      "eval_loss": 1.2189699411392212,
      "eval_runtime": 42.8779,
      "eval_samples_per_second": 18.261,
      "eval_steps_per_second": 9.142,
      "step": 1800
    },
    {
      "epoch": 4.719846841097639,
      "grad_norm": 3.9086356163024902,
      "learning_rate": 1.7485844394943717e-07,
      "loss": 1.154,
      "step": 1850
    },
    {
      "epoch": 4.847479259731972,
      "grad_norm": 3.258469343185425,
      "learning_rate": 5.291595955592033e-08,
      "loss": 1.1454,
      "step": 1900
    },
    {
      "epoch": 4.975111678366305,
      "grad_norm": 3.513216972351074,
      "learning_rate": 1.7221988728843842e-09,
      "loss": 1.1485,
      "step": 1950
    }
  ],
  "logging_steps": 50,
  "max_steps": 1960,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.4289614354120704e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
