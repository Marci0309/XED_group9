{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ebc759c4da84602f",
      "metadata": {
        "collapsed": false,
        "id": "ebc759c4da84602f"
      },
      "source": [
        "\n",
        " # Hugging Face Transformers - A Complete Guide\n",
        "\n",
        " This notebook provides a complete guide on how to use Hugging Face Transformers to perform common Natural Language Processing (NLP) tasks such as:\n",
        " - Sentiment Analysis\n",
        " - Text Summarization\n",
        " - Question Answering\n",
        " - Text Translation\n",
        " - Text Generation\n",
        "\n",
        "\n",
        "Additionally, it will demonstrate how to fine-tune a pre-trained model on a custom dataset for specific tasks.\n",
        "\n",
        "# 1. Installing Necessary Libraries\n",
        "Before we can start, we need to install the required Python packages. We will use the Hugging Face `transformers` and `datasets` libraries along with `torch`, which is the backend framework that runs the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d5c47582c38a640d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-11T13:11:10.902672300Z",
          "start_time": "2024-09-11T13:11:06.500292200Z"
        },
        "id": "d5c47582c38a640d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (4.56.2)\n",
            "Requirement already satisfied: datasets in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (3.4.1)\n",
            "Requirement already satisfied: torch in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (2.3.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: xxhash in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: sympy in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from requests->transformers) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/joelboer/Library/Python/3.11/lib/python/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1370508aff367b36",
      "metadata": {
        "collapsed": false,
        "id": "1370508aff367b36"
      },
      "source": [
        "# 2. Using Hugging Face Pipelines\n",
        "\n",
        "Hugging Face provides a high-level abstraction called `pipeline`. The `pipeline` is designed to allow you to quickly apply a model to a task without needing to worry about the underlying details.\n",
        "\n",
        "You can use the `pipeline` function to load a pre-trained model for different tasks such as sentiment analysis, text generation, summarization, etc.\n",
        "\n",
        "Let's start by importing the `pipeline` function from the Hugging Face Transformers library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "397273d8a6e1aae7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-11T13:11:23.664156Z",
          "start_time": "2024-09-11T13:11:10.901679Z"
        },
        "id": "397273d8a6e1aae7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/bg/3dls4d8d6r1371bvyt8fj25c0000gr/T/ipykernel_31446/1271987455.py\", line 1, in <module>\n",
            "    from transformers import pipeline\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/transformers/utils/import_utils.py\", line 2302, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/transformers/utils/import_utils.py\", line 2330, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/transformers/pipelines/__init__.py\", line 26, in <module>\n",
            "    from ..image_processing_utils import BaseImageProcessor\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/transformers/image_processing_utils.py\", line 22, in <module>\n",
            "    from .image_transforms import center_crop, normalize, rescale\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/transformers/image_transforms.py\", line 48, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/__init__.py\", line 45, in <module>\n",
            "    from tensorflow._api.v2 import __internal__\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.__internal__ import autograph\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
            "    from tensorflow.python.autograph.utils import ag_logging\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
            "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
            "    from tensorflow.python.framework import ops\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/framework/ops.py\", line 50, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/eager/context.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/eager/execute.py\", line 21, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/tensorflow/python/framework/dtypes.py\", line 21, in <module>\n",
            "    import ml_dtypes\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ml_dtypes/__init__.py\", line 32, in <module>\n",
            "    from ml_dtypes._finfo import finfo\n",
            "  File \"/Users/joelboer/Library/Python/3.11/lib/python/site-packages/ml_dtypes/_finfo.py\", line 19, in <module>\n",
            "    from ml_dtypes._ml_dtypes_ext import bfloat16\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core._multiarray_umath failed to import",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "numpy.core.umath failed to import",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/Users/joelboer/Desktop/LLM/XED_group9/huggingface_guide.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joelboer/Desktop/LLM/XED_group9/huggingface_guide.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtransformers\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joelboer/Desktop/LLM/XED_group9/huggingface_guide.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/utils/import_utils.py:2302\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module:\n\u001b[1;32m   2301\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2302\u001b[0m         module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   2303\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2304\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/utils/import_utils.py:2332\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2330\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   2331\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 2332\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/utils/import_utils.py:2330\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_get_module\u001b[39m(\u001b[39mself\u001b[39m, module_name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m   2329\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2330\u001b[0m         \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   2331\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   2332\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
            "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/pipelines/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdynamic_module_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m get_class_from_dynamic_module\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m PreTrainedFeatureExtractor\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage_processing_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m BaseImageProcessor\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfiguration_auto\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m AutoConfig\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction_auto\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m FEATURE_EXTRACTOR_MAPPING, AutoFeatureExtractor\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/image_processing_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mimage_processing_base\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m BatchFeature, ImageProcessingMixin\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mimage_transforms\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m center_crop, normalize, rescale\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mimage_utils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m ChannelDimension, get_image_size\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m logging\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/transformers/image_transforms.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtf\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     51\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mjnp\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tf2 \u001b[39mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[39m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m audio\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msys\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m dispatch\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39msys\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mag_ctx\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m control_status_ctx \u001b[39m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tf_convert \u001b[39m# line: 493\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mlocal()\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext_managers\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograph\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensor_list\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m dynamic_list_append\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/framework/ops.py:50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tf2\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[0;32m---> 50\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m core\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m monitoring\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/eager/context.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m cancellation\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m execute\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m executor\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m monitoring\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/eager/execute.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m core\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m dtypes\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tensor_conversion_registry\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m tensor_shape\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/tensorflow/python/framework/dtypes.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdataclasses\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtyping\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Type, Sequence, Optional\n\u001b[0;32m---> 21\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m types_pb2\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/ml_dtypes/__init__.py:32\u001b[0m\n\u001b[1;32m     16\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m__version__\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbfloat16\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39m'\u001b[39m\u001b[39muint4\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtyping\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Type\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_finfo\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m finfo\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_iinfo\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m iinfo\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ml_dtypes_ext\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m bfloat16\n",
            "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/ml_dtypes/_finfo.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Overload of numpy.finfo to handle dtypes defined in ml_dtypes.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtyping\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Dict\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ml_dtypes_ext\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m bfloat16\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ml_dtypes_ext\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m float8_e4m3b11fnuz\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mml_dtypes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ml_dtypes_ext\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m float8_e4m3fn\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.umath failed to import"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d241505041a6a8",
      "metadata": {
        "collapsed": false,
        "id": "b1d241505041a6a8"
      },
      "source": [
        "### Task 1: Sentiment Analysis\n",
        "Sentiment Analysis is the task of classifying a given text into positive, negative, or neutral sentiments.\n",
        "\n",
        "In this example, we will use a pre-trained model for sentiment analysis. The `pipeline` will automatically download and load a model that has been pre-trained on a large dataset to perform this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08c573b7d61fca0",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.666148400Z"
        },
        "id": "c08c573b7d61fca0"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis')\n",
        "result = classifier(\"I love the Large Language Model course!\")\n",
        "print(f\"Sentiment Analysis Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347a60822e415e0b",
      "metadata": {
        "collapsed": false,
        "id": "347a60822e415e0b"
      },
      "source": [
        "### Task 2: Text Summarization\n",
        "\n",
        "Notice the errors:\n",
        "   - 'Using a pipeline without specifying a model name and revision in production is not recommended.'\n",
        "   - 'FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default.\n",
        "\n",
        "The first error is a warning that suggests specifying the model name and revision when using a pipeline in production. This is important to ensure reproducibility and consistency in your results. Huggingface's standard libraries and versions change frequently, so it's a good practice to specify the model name and revision. This is specified in the cell below, where model is the model name, and revision is the version of the model.\n",
        "\n",
        "`clean_up_tokenization_spaces` removes spaces before punctuations and adds spaces after these punctuations. Only relevant if `add_prefix_space` is `True` in the tokenizer. It makes sure the text is human-readable without odd spacing issues.\n",
        "\n",
        "Furthermore, the gpu is not yet selected, so we need to do that too.\n",
        "\n",
        "Text Summarization is the task of creating a shorter version of a long text while preserving the main content. This can be useful when you need to condense large articles or reports.\n",
        "\n",
        "We'll use the `summarization` pipeline for this task, which leverages models that are fine-tuned specifically for generating summaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "699a10d6d117e02",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.669143100Z"
        },
        "id": "699a10d6d117e02"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-small\" # or gpt-2, facebook/barg-large-cnn, etc.\n",
        "revision = \"main\"  # or a specific commit hash, version, or tag\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=model_name, revision=revision, device=device)\n",
        "\n",
        "text = \"Machine learning is the study of computer algorithms that improve automatically through experience. It is seen as a part of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.\"\n",
        "\n",
        "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "print(f\"Summary: {summary[0]['summary_text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a77ad3e38ad451e",
      "metadata": {
        "collapsed": false,
        "id": "4a77ad3e38ad451e"
      },
      "source": [
        "### Task 3: Question-Answering\n",
        "\n",
        "Question Answering involves answering a question based on a provided context. This task is useful for systems like chatbots or information retrieval systems where the goal is to answer specific queries from a given body of text.\n",
        "\n",
        "We'll use the `question-answering` pipeline for this task, which requires both a question and a context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfde0988d5c15cc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-11T13:11:23.682116Z",
          "start_time": "2024-09-11T13:11:23.672135200Z"
        },
        "id": "1bfde0988d5c15cc"
      },
      "outputs": [],
      "source": [
        "question_answerer = pipeline(\"question-answering\", device=device)\n",
        "\n",
        "context = \"Machine learning is a subset of artificial intelligence, which involves using statistical techniques to give computer systems the ability to 'learn' from data, without being explicitly programmed.\"\n",
        "\n",
        "question = \"What is machine learning?\"\n",
        "answer = question_answerer(question=question, context=context)\n",
        "print(f\"Answer: {answer['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ded074cce4ae141",
      "metadata": {
        "collapsed": false,
        "id": "1ded074cce4ae141"
      },
      "source": [
        "### Task 4: Text Translation\n",
        "\n",
        "Text Translation is the task of converting text from one language to another. Hugging Face provides translation pipelines for a wide range of languages.\n",
        "\n",
        "In this example, we will translate a sentence from English to French using the `translation_en_to_fr` pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c77152427cad9e",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.675124600Z"
        },
        "id": "f7c77152427cad9e"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(\"translation_en_to_fr\", device=device)\n",
        "\n",
        "translation = translator(\"Hello, how are you?\")\n",
        "print(f\"Translation: {translation[0]['translation_text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478c10561adfcaef",
      "metadata": {
        "collapsed": false,
        "id": "478c10561adfcaef"
      },
      "source": [
        "### Task 5: Text Generation\n",
        "Text Generation involves generating coherent text from a given prompt. Models like GPT-2 are commonly used for this task.\n",
        "\n",
        "We'll use the text-generation pipeline to generate text based on an initial prompt.\n",
        "\n",
        "Let's run the following cell to generate text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6648e9ad31cad9f4",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.678118500Z"
        },
        "id": "6648e9ad31cad9f4"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\"text-generation\", device=device)\n",
        "\n",
        "generated_text = generator(\"Artificial intelligence will revolutionize the future of technology\")\n",
        "print(f\"Generated Text: {generated_text[0]['generated_text']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23025de743370a0f",
      "metadata": {
        "collapsed": false,
        "id": "23025de743370a0f"
      },
      "source": [
        "# 3. Fine-Tuning Pre-trained Models\n",
        "While the pre-trained models provided by Hugging Face are powerful, you may want to fine-tune them for a specific task or dataset.\n",
        "\n",
        "Fine-tuning involves taking a pre-trained model and training it further on your own data. This can improve the model’s performance for specific use cases.\n",
        "\n",
        "For this section, we’ll load the IMDB dataset (which contains movie reviews) and fine-tune a pre-trained model for sentiment classification.\n",
        "\n",
        "### Step 1: Load Dataset\n",
        "We'll use Hugging Face's datasets library to load the IMDB dataset.\n",
        "\n",
        "Datasets from the dataset library often come with pre-defined splits of the data, such as `train` and `test` sets.\n",
        "\n",
        "It is possible to filter or slice datasets to focus on specific subsets of the data, using the `select` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02c5a5d660751f6",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.684099300Z"
        },
        "id": "b02c5a5d660751f6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100))  # Using a subset for quick fine-tuning\n",
        "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404f2e557f938c88",
      "metadata": {
        "collapsed": false,
        "id": "404f2e557f938c88"
      },
      "source": [
        "### Step 2: Tokenize the Dataset\n",
        "The dataset needs to be tokenized before it can be fed into the model. Tokenization converts the text data into numerical format (tokens) that the model can process.\n",
        "\n",
        "We'll use the `AutoTokenizer` class from HuggingFace to tokenize the data. The `AutoTokenizer` class automatically selects the appropriate tokenizer for the model based on the `model_name`.\n",
        "\n",
        "Tokenization or transformation of the dataset can be done using the `map` method, which applies a function to all the elements of the dataset. This is easily done by defining a function that tokenizes the text data and then applying it to the dataset. When `batched=True`, the function will be applied to batches of data, which can improve performance by applying the function in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76bfbf6e30ed6c40",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.687091400Z"
        },
        "id": "76bfbf6e30ed6c40"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # print(examples[\"text\"][0])\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20413a582b139a0e",
      "metadata": {
        "collapsed": false,
        "id": "20413a582b139a0e"
      },
      "source": [
        "### Step 3: Load a Pre-trained Model\n",
        "Now that the data is tokenized, we'll load a pre-trained model that we'll fine-tune for sentiment classification.\n",
        "\n",
        "We'll use distilbert-base-uncased for this task.\n",
        "\n",
        "We need to import `AutoModelForSequenceClassification` for that. The key feature of this class is that it adds a classification head on top of the pre-trained transformer model to allow it to classify sequences into one or more categories (e.g., positive/negative sentiment, spam/ham, etc.). The `from_pretrained` method loads the pre-trained model with the specified configuration. The `num_labels` parameter specifies the number of labels in the classification task (binary in this case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c217ddcb27c998d",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.689086Z"
        },
        "id": "7c217ddcb27c998d"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b466e12de8bfef",
      "metadata": {
        "collapsed": false,
        "id": "8b466e12de8bfef"
      },
      "source": [
        "### Step 4: Set Up the Trainer\n",
        "Hugging Face provides the Trainer class to help with the training and fine-tuning of models. We need to set up the trainer by providing the model, training arguments, and the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314f8aad08895c6e",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.691080400Z"
        },
        "id": "314f8aad08895c6e"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluate after each epoch\n",
        "    learning_rate=2e-5,              # Learning rate\n",
        "    per_device_train_batch_size=8,   # Batch size for training\n",
        "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
        "    num_train_epochs=1,              # Number of epochs\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4205eac4d06f8ae5",
      "metadata": {
        "collapsed": false,
        "id": "4205eac4d06f8ae5"
      },
      "source": [
        "### Step 5: Fine-tune the Model\n",
        "Now that the trainer is set up, we can start the fine-tuning process.\n",
        "\n",
        "Run the following cell to fine-tune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3125c17af30c4b",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.693075300Z"
        },
        "id": "3c3125c17af30c4b"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "197d2fb4351c32ea",
      "metadata": {
        "collapsed": false,
        "id": "197d2fb4351c32ea"
      },
      "source": [
        "### Step 6: Evaluate the Model\n",
        "After training, we can evaluate the model’s performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d341d66e17736303",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.695070100Z"
        },
        "id": "d341d66e17736303"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1UJ8GcJSPhmt",
      "metadata": {
        "id": "1UJ8GcJSPhmt"
      },
      "source": [
        "### Step 7: Try out model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZTssehqcPd8R",
      "metadata": {
        "id": "ZTssehqcPd8R"
      },
      "outputs": [],
      "source": [
        "input_string = \"I really liked this tutorial!\"\n",
        "\n",
        "# Tokenize the input string\n",
        "inputs = tokenizer(input_string, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Get predictions (logits)\n",
        "with torch.no_grad():  # Disable gradient computation since we're just doing inference\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "predicted_label = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "\n",
        "print(f\"Predicted label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53007a617ec9423",
      "metadata": {
        "collapsed": false,
        "id": "53007a617ec9423"
      },
      "source": [
        "### Step 8. Saving the Fine-tuned Model\n",
        "After training, it is often useful to save the fine-tuned model, so you can use it later without needing to re-train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e5c82ccd0913cc",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-09-11T13:11:23.699060Z"
        },
        "id": "a4e5c82ccd0913cc"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./fine-tuned-model\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
